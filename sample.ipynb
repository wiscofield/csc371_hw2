{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grateful-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_fashion_mnist():\n",
    "    \"\"\"\n",
    "    Loads Fashion MNIST dataset.\n",
    "    \n",
    "    Adapted from: https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "    \"\"\"\n",
    "    TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "    TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'    \n",
    "    TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "    TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "    with gzip.open(TRAIN_LABELS, 'rb') as tr_labels_file, gzip.open(TEST_LABELS, 'rb') as ts_labels_file:\n",
    "        train_labels = np.frombuffer(tr_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "        test_labels = np.frombuffer(ts_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(TRAIN_IMAGES, 'rb') as tr_images_file, gzip.open(TEST_IMAGES, 'rb') as ts_images_file:\n",
    "        train_images = np.frombuffer(tr_images_file.read(), dtype=np.uint8, offset=16).reshape(len(train_labels), 784)\n",
    "        test_images = np.frombuffer(ts_images_file.read(), dtype=np.uint8, offset=16).reshape(len(test_labels), 784)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(image_example):\n",
    "    \"\"\" Pretty prints a Fashion MNIST example.\n",
    "\n",
    "    Parameters:\n",
    "        image_example: a 1x784 numpy array corresponding to the features of\n",
    "                       a single image.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    print(np.array_str(image_example, precision=1, max_line_width=116))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portuguese-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usage_example():\n",
    "    \"\"\" Example of how to load and parse Fashion MNIST data. \"\"\"\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_fashion_mnist()\n",
    "\n",
    "    # train_images is a 60,000 x 784 numpy matrix. There are 60k\n",
    "    # rows in the matrix, each row corresponding to a single example.\n",
    "    # There are 784 columns, each corresponding to the value of a\n",
    "    # single pixel in the 28x28 image after it has been \"flattened\".\n",
    "    print(\"Dimensions of training set feature matrix:\", train_images.shape)\n",
    "\n",
    "    # The labels for each example are maintained separately in train_labels.\n",
    "    # This is a 60,000 x 1 numpy matrix, where each element is the label\n",
    "    # for the corresponding training example.\n",
    "    print(\"Dimensions of training set label matrix:\", train_labels.shape)\n",
    "\n",
    "    # Example of how to access a individual training example (in this case,\n",
    "    # we pick an example at a random index). We could use print to output the\n",
    "    # raw pixel values to the screen, but pretty_print formats the data in \n",
    "    # a nicer way: if you squint, you may be able to make out the contours of\n",
    "    # the fashion article in the matrix data.\n",
    "    EXAMPLE_INDEX = np.random.randint(60000)\n",
    "    print(\"Features of training example at index {}:\\n\".format(EXAMPLE_INDEX))\n",
    "    pretty_print(train_images[EXAMPLE_INDEX])\n",
    "\n",
    "    # And here's the label that goes with that training example\n",
    "    print(\"\\nLabel of training example at index {}:\".format(EXAMPLE_INDEX), train_labels[EXAMPLE_INDEX], '\\n')\n",
    "\n",
    "    # Finally, let's visualize the example we've picked as a 28x28 image\n",
    "    plt.figure()\n",
    "    plt.imshow(train_images[EXAMPLE_INDEX].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    # The test_images/test_labels are organized in the same way, but only contain 10k\n",
    "    # examples. Don't touch this data until your model is frozen! Perform all\n",
    "    # cross-validation, model selection, hyperparameter tuning etc. on the 60k\n",
    "    # training set. Use the test set simply for reporting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blond-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training set feature matrix: (60000, 784)\n",
      "Dimensions of training set label matrix: (60000,)\n",
      "Features of training example at index 28070:\n",
      "\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   1   0   2  60  92  18   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   1   0   1   4   7   2   0   0   1   2   0  53 181 178 152   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   1   1   0   0 170 168 174   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   1   0   1   0  34  83   1   0   1   0   0   4   0  82 210 206  97   0   0   0   0   0   0   1   1   0   0   0\n",
      "   1   0   0   0  40 170  18   0   1   0   0   0   0   0 255 172 110   0   0   1   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   7 167  30   0   2   1   1   0   1   0  83 234 149  21   0   0   0   0   0   0   0   0   0   0\n",
      "  11  12   0   0   1 154  21   0   0   0   0   0   0   0   0 131 188 100   1  15  14  30  50  63  93 129 190  77\n",
      "  66 171 162 149 123 122  90  92  95  93 100 108 109 141 136 201 242 244 208 242 216 216 221 214 208 188 213  44\n",
      "   0   0  24  57  76  80 112 121 125 133 129 128 131 113 102  60  24   8   0  41 108  50  31  17   2   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "Label of training example at index 28070: 5 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAANhklEQVR4nO3dbYxc5XnG8evyem03BlNsE2OMIYRSpahNnbIyjUAVLSoi/lCTqKK4EnIlqo3aUCUNqooSqUHqF1QlRK3UpnJiK06VEkUhCKtFLY4ViaYvlAW5xoakJtQUu4sXYgQ2YHtf7n7YQ7SBPc+M58wbuf8/aTQz554z5+awl8/MeZnHESEAP/2WDLoBAP1B2IEkCDuQBGEHkiDsQBJL+7mwZV4eK7Syn4sEUjmt13U2znixWqOw275Z0l9KGpH0lYi4t/T6FVqpa31jk0UCKHgs9tXWOv4Yb3tE0l9L+oikqyVts311p+8HoLeafGffLOnZiHguIs5K+oakrd1pC0C3NQn7BkkvLHh+tJr2E2yP256wPTGtMw0WB6CJnu+Nj4gdETEWEWOjWt7rxQGo0STsxyRtXPD80moagCHUJOyPS7rK9hW2l0m6TdKe7rQFoNs6PvQWETO275T0z5o/9LYrIg51rTMAXdXoOHtEPCzp4S71AqCHOF0WSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kESjIZttH5F0UtKspJmIGOtGUwC6r1HYK78eES934X0A9BAf44EkmoY9JD1i+wnb44u9wPa47QnbE9M603BxADrV9GP89RFxzPZ7Je21/f2IeHThCyJih6QdkrTKq6Ph8gB0qNGWPSKOVfdTkh6UtLkbTQHovo7Dbnul7fPfeizpJkkHu9UYgO5q8jF+naQHbb/1Pn8fEf/Ula4AdF3HYY+I5yT9chd7AdBDHHoDkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiSZDNqNf5ofFrhdRX1syUpz19JZrivVXryj/iWz41nPF+szki8U6+qfllt32LttTtg8umLba9l7bh6v7C3vbJoCm2vkY/1VJN79t2t2S9kXEVZL2Vc8BDLGWYY+IRyWdeNvkrZJ2V493S7qlu20B6LZOv7Ovi4jJ6vGLktbVvdD2uKRxSVqh93S4OABNNd4bHxEhqXYPUUTsiIixiBgb1fKmiwPQoU7Dftz2ekmq7qe61xKAXug07Hskba8eb5f0UHfaAdArLb+z275f0g2S1to+Kulzku6V9E3bd0h6XtKtbS+x1THjktLx5Bbv66Wj5fpoeVXMnT5TKM4W522p1Tpxi3+To37507+xqTjryruOFuvL5srH6X/w4YuL9St/l+Psw6Jl2CNiW03pxi73AqCHOF0WSIKwA0kQdiAJwg4kQdiBJPp/iWvp8FkP3zemzzaqD1TMdTzr6HeeKNZPfPrnivXZufL24JI1r55zTxgMtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kET/j7OXLudsdQy+wbxLPviBYv2lzeUfyF2z8z86Xnajn4Jug0eX1b91i/MHZh64qFj/nT9+pFh/Y7b860MPfPqG2tr6+/6tOO9Qa3KpttS7800K2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLvriGbGxybjOXln5Je+rGXyvV/rB3hauDDEje5Fn/Nzn8v1v/kz39YrF934GPF+vR559xS+3p8/sLA3rtH2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBI/Pb8b34IPlY8XT89eWqzHz55fX2x1nL3VkMvq/HfhJTUayrrV/4+xP/uDYv1vPvtXxfq2l8Zra0s3ltf5zAvl4aTfjce6B6nllt32LttTtg8umHaP7WO291e3Lb1tE0BT7XyM/6qkmxeZ/sWI2FTdHu5uWwC6rWXYI+JRSSf60AuAHmqyg+5O2weqj/m1P+Bme9z2hO2JaZ1psDgATXQa9i9JulLSJkmTkr5Q98KI2BERYxExNqryjxMC6J2Owh4RxyNiNiLmJH1Z0ubutgWg2zoKu+31C55+VNLButcCGA4tj7Pbvl/SDZLW2j4q6XOSbrC9SVJIOiLp4+0szCMjGll1QeEF5X97Zl95pZ3FLGruzTeL9ZOnfqZYv/jUjzpetuZmO5+3qYbHotd8pXy9+20fvLNY33zN4draodvKv+V/yeePFesja9cW68Vx7S9aXZz17MWF8yoknb2gHJ3XLivXT76/vrcPb/5+cd7Df/sLtbXZf6gf36Bl2CNi2yKTd7aaD8Bw4XRZIAnCDiRB2IEkCDuQBGEHkujrJa6zq1botRvrD7fM/v7LxflPnV5fW3vjVPnsvCWTK8rN/W+5/H+/tbK2FksuK84bI+X3dosrXFuMilyut7jC9c3LpssvmCm/wW9f+5/F+h+u+Zfa2ugf7SnO+7XbrynWt13wYLG+942fL9ZLVi0pH6r90Wz5N7JfnXlPsX7g5Iba2rUX/E9x3qlnL6+tjZyu/2Niyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTj6+HO8q7w6rvWNHc+/9Ir644uvf+C9xXnfXFs+pWCuxRkHpy6vP948s6K8DmNpuT7XYn63ONatwuwxUn7vZa+UTwJY+kZ50WsOzRTr5x06XlubmyqfVzH3+uvlhW/+pWL5hZvqL1O95F9PF+dddvxUse4TrxbrMy3+23p12fNjsU+vxYlF/2DYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEu+q4+wAyjjODoCwA1kQdiAJwg4kQdiBJAg7kARhB5Ig7EASLcNue6Pt79p+2vYh25+spq+2vdf24er+wt63C6BT7WzZZyTdFRFXS/pVSZ+wfbWkuyXti4irJO2rngMYUi3DHhGTEfFk9fikpGckbZC0VdLu6mW7Jd3Sox4BdME5jfVm+32SPiTpMUnrImKyKr0oaV3NPOOSxiVphcrjXwHonbZ30Nk+T9IDkj4VEa8trMX81TSLXlETETsiYiwixkbVYoRCAD3TVthtj2o+6F+PiG9Xk4/bXl/V10ua6k2LALqhnb3xlrRT0jMRcd+C0h5J26vH2yU91P32AHRLO9/Zr5N0u6SnbO+vpn1G0r2Svmn7DknPS7q1Jx0C6IqWYY+I70mqG6WAX6IA3iU4gw5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk2hmffaPt79p+2vYh25+spt9j+5jt/dVtS+/bBdCpdsZnn5F0V0Q8aft8SU/Y3lvVvhgRn+9dewC6pZ3x2SclTVaPT9p+RtKGXjcGoLvO6Tu77fdJ+pCkx6pJd9o+YHuX7Qtr5hm3PWF7YlpnmnULoGNth932eZIekPSpiHhN0pckXSlpk+a3/F9YbL6I2BERYxExNqrlzTsG0JG2wm57VPNB/3pEfFuSIuJ4RMxGxJykL0va3Ls2ATTVzt54S9op6ZmIuG/B9PULXvZRSQe73x6Abmlnb/x1km6X9JTt/dW0z0jaZnuTpJB0RNLHe9AfgC5pZ2/89yR5kdLD3W8HQK9wBh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0T/Fma/JOn5BZPWSnq5bw2cm2HtbVj7kuitU93s7fKIuGixQl/D/o6F2xMRMTawBgqGtbdh7Uuit071qzc+xgNJEHYgiUGHfceAl18yrL0Na18SvXWqL70N9Ds7gP4Z9JYdQJ8QdiCJgYTd9s22f2D7Wdt3D6KHOraP2H6qGoZ6YsC97LI9Zfvggmmrbe+1fbi6X3SMvQH1NhTDeBeGGR/ouhv08Od9/85ue0TSf0v6TUlHJT0uaVtEPN3XRmrYPiJpLCIGfgKG7V+TdErS1yLiF6tpfyHpRETcW/1DeWFE/OmQ9HaPpFODHsa7Gq1o/cJhxiXdIun3NMB1V+jrVvVhvQ1iy75Z0rMR8VxEnJX0DUlbB9DH0IuIRyWdeNvkrZJ2V493a/6Ppe9qehsKETEZEU9Wj09KemuY8YGuu0JffTGIsG+Q9MKC50c1XOO9h6RHbD9he3zQzSxiXURMVo9flLRukM0souUw3v30tmHGh2bddTL8eVPsoHun6yPiVyR9RNInqo+rQynmv4MN07HTtobx7pdFhhn/sUGuu06HP29qEGE/JmnjgueXVtOGQkQcq+6nJD2o4RuK+vhbI+hW91MD7ufHhmkY78WGGdcQrLtBDn8+iLA/Lukq21fYXibpNkl7BtDHO9heWe04ke2Vkm7S8A1FvUfS9urxdkkPDbCXnzAsw3jXDTOuAa+7gQ9/HhF9v0naovk98j+U9NlB9FDT1/sl/Vd1OzTo3iTdr/mPddOa37dxh6Q1kvZJOizpO5JWD1FvfyfpKUkHNB+s9QPq7XrNf0Q/IGl/ddsy6HVX6Ksv643TZYEk2EEHJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0n8PyzLLTk5yV50AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "usage_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-voltage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
