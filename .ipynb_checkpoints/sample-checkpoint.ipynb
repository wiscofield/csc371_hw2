{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_fashion_mnist():\n",
    "    \"\"\"\n",
    "    Loads Fashion MNIST dataset.\n",
    "    \n",
    "    Adapted from: https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "    \"\"\"\n",
    "    TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "    TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'    \n",
    "    TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "    TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "    with gzip.open(TRAIN_LABELS, 'rb') as tr_labels_file, gzip.open(TEST_LABELS, 'rb') as ts_labels_file:\n",
    "        train_labels = np.frombuffer(tr_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "        test_labels = np.frombuffer(ts_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(TRAIN_IMAGES, 'rb') as tr_images_file, gzip.open(TEST_IMAGES, 'rb') as ts_images_file:\n",
    "        train_images = np.frombuffer(tr_images_file.read(), dtype=np.uint8, offset=16).reshape(len(train_labels), 784)\n",
    "        test_images = np.frombuffer(ts_images_file.read(), dtype=np.uint8, offset=16).reshape(len(test_labels), 784)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(image_example):\n",
    "    \"\"\" Pretty prints a Fashion MNIST example.\n",
    "\n",
    "    Parameters:\n",
    "        image_example: a 1x784 numpy array corresponding to the features of\n",
    "                       a single image.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    print(np.array_str(image_example, precision=1, max_line_width=116))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usage_example():\n",
    "    \"\"\" Example of how to load and parse Fashion MNIST data. \"\"\"\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_fashion_mnist()\n",
    "\n",
    "    # train_images is a 60,000 x 784 numpy matrix. There are 60k\n",
    "    # rows in the matrix, each row corresponding to a single example.\n",
    "    # There are 784 columns, each corresponding to the value of a\n",
    "    # single pixel in the 28x28 image after it has been \"flattened\".\n",
    "    print(\"Dimensions of training set feature matrix:\", train_images.shape)\n",
    "\n",
    "    # The labels for each example are maintained separately in train_labels.\n",
    "    # This is a 60,000 x 1 numpy matrix, where each element is the label\n",
    "    # for the corresponding training example.\n",
    "    print(\"Dimensions of training set label matrix:\", train_labels.shape)\n",
    "\n",
    "    # Example of how to access a individual training example (in this case,\n",
    "    # we pick an example at a random index). We could use print to output the\n",
    "    # raw pixel values to the screen, but pretty_print formats the data in \n",
    "    # a nicer way: if you squint, you may be able to make out the contours of\n",
    "    # the fashion article in the matrix data.\n",
    "    EXAMPLE_INDEX = np.random.randint(60000)\n",
    "    print(\"Features of training example at index {}:\\n\".format(EXAMPLE_INDEX))\n",
    "    pretty_print(train_images[EXAMPLE_INDEX])\n",
    "\n",
    "    # And here's the label that goes with that training example\n",
    "    print(\"\\nLabel of training example at index {}:\".format(EXAMPLE_INDEX), train_labels[EXAMPLE_INDEX], '\\n')\n",
    "\n",
    "    # Finally, let's visualize the example we've picked as a 28x28 image\n",
    "    plt.figure()\n",
    "    plt.imshow(train_images[EXAMPLE_INDEX].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    # The test_images/test_labels are organized in the same way, but only contain 10k\n",
    "    # examples. Don't touch this data until your model is frozen! Perform all\n",
    "    # cross-validation, model selection, hyperparameter tuning etc. on the 60k\n",
    "    # training set. Use the test set simply for reporting performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
